- id: doi:10.1371/journal.pcbi.1007128
  type: paper
  description: "test description. ![GitHub Repo stars](https://img.shields.io/github/stars/daijifeng001/R-FCN)\
    \ test stars. <a href=\"https://www.baidu.com\"><button style=\"padding: 10px; display: inline-flex; font-family: var(--heading); font-weight: var(--semi-bold);\
    \ background-color: #0ea5e9; color: white; border: none; border-radius: 10px; margin: 5px; gap: 10px; max-width: calc(100% - 5px - 5px);\
    \ cursor: pointer;\">Click Me</button></a>"
  date: 2020-12-4
  # image: https://journals.plos.org/ploscompbiol/article/figure/image?size=inline&id=info:doi/10.1371/journal.pcbi.1007128.g001&rev=2
  image: images/different_items.gif
  buttons:
    - type: manubot
      link: https://greenelab.github.io/meta-review/
    - type: source
      text: Manuscript Source
      link: https://github.com/greenelab/meta-review
    - type: website
      link: http://manubot.org/
      style: rich
  tags:
    - open science
    - collaboration
  repo: greenelab/meta-review


- id: arxiv:1605.06409
  type: paper
  publisher: NeurIPS 2016
  image: images/1605.06409.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/daijifeng001/R-FCN)-
    \ The 3rd most influential paper in NeurIPS 2016-
    \ Pytorch visual operator library"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1605.06409
    - type: source
      text: Code
      link: https://github.com/daijifeng001/R-FCN

- id: arxiv:2010.04159
  type: paper
  publisher: ICLR 2021 (Oral)
  image: images/2010.04159.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/fundamentalvision/Deformable-DETR)-
    \ The 2nd most influential paper in ICLR 2021"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2010.04159
    - type: source
      text: Code
      link: https://github.com/fundamentalvision/Deformable-DETR

- id: arxiv:1703.06211
  type: paper
  publisher: ICCV 2017 (Oral)
  image: images/1703.06211.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/msracver/Deformable-ConvNets)-
    \ The 6th most influential paper in ICCV 2017-
    \ Pytorch visual operator library"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1703.06211
    - type: source
      text: Code
      link: https://github.com/msracver/Deformable-ConvNets

- id: arxiv:2211.05778
  type: paper
  publisher: CVPR 2023 (Highlight)
  image: images/2211.05778.png
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2211.05778

- id: arxiv:1906.07155
  type: paper
  publisher: CVPR 2019
  image: images/1906.07155.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/open-mmlab/mmdetection)"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1906.07155
    - type: source
      text: Code
      link: https://github.com/open-mmlab/mmdetection

- id: arxiv:1512.04412
  type: paper
  publisher: CVPR 2016 (Oral)
  image: images/1512.04412.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/daijifeng001/MNC)-
    \ 1st place winner of the COCO 2015 segmentation challenge. (0.36 sec/image test speed using VGG-16 net)"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1512.04412
    - type: source
      text: Code
      link: https://github.com/daijifeng001/MNC

- id: arxiv:1811.11168
  type: paper
  publisher: CVPR 2019
  image: images/1811.11168.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/msracver/Deformable-ConvNets)"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1811.11168
    - type: source
      text: Code
      link: https://github.com/msracver/Deformable-ConvNets

- id: arxiv:1711.11575
  type: paper
  publisher: CVPR 2018 (Oral)
  image: images/1711.11575.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/msracver/Relation-Networks-for-Object-Detection)"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1711.11575
    - type: source
      text: Code
      link: https://github.com/msracver/Relation-Networks-for-Object-Detection

- id: arxiv:1611.07709
  type: paper
  publisher: CVPR 2017 (Spotlight)
  image: images/1611.07709.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/msracver/FCIS)"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1611.07709
    - type: source
      text: Code
      link: https://github.com/msracver/FCIS

- id: arxiv:1503.01640
  type: paper
  publisher: ICCV 2015
  image: images/1503.01640.png
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1503.01640

- id: arxiv:1604.05144
  type: paper
  publisher: CVPR 2016 (Oral)
  image: images/1604.05144.png
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1604.05144
    - type: source
      text: Code
      link: http://www.jifengdai.org/downloads/scribble_sup/

- id: arxiv:1611.07715
  type: paper
  publisher: CVPR 2017
  image: images/1611.07715.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/msracver/Deep-Feature-Flow)"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1611.07715
    - type: source
      text: Code
      link: https://github.com/msracver/Deep-Feature-Flow

- id: arxiv:1703.10025
  type: paper
  publisher: ICCV 2017
  image: images/1703.10025.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/msracver/Flow-Guided-Feature-Aggregation)"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1703.10025
    - type: source
      text: Code
      link: https://github.com/msracver/Flow-Guided-Feature-Aggregation

- id: arxiv:1412.1283
  type: paper
  publisher: CVPR 2015
  image: images/1412.1283.png
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1412.1283

- id: arxiv:1908.08530
  type: paper
  publisher: ICLR 2020
  image: images/1908.08530.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/jackroos/VL-BERT)"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1908.08530
    - type: source
      text: Code
      link: https://github.com/jackroos/VL-BERT

- id: arxiv:2112.01522
  type: paper
  publisher: CVPR 2022
  image: images/2112.01522.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/fundamentalvision/Uni-Perceiver)"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2112.01522
    - type: source
      text: Code
      link: https://github.com/fundamentalvision/Uni-Perceiver

- id: arxiv:2206.04674
  type: paper
  publisher: NeurIPS 2022 (Spotlight)
  image: images/2206.04674.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/fundamentalvision/Uni-Perceiver)"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2206.04674
    - type: source
      text: Code
      link: https://github.com/fundamentalvision/Uni-Perceiver

- id: arxiv:2211.09808
  type: paper
  publisher: CVPR 2023 (Highlight)
  image: images/2211.09808.png
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2211.09808

- id: arxiv:2305.11175
  type: paper
  publisher: Arxiv Tech Report 2023
  image: images/2305.11175.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/OpenGVLab/VisionLLM)"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2305.11175
    - type: source
      text: Code
      link: https://github.com/OpenGVLab/VisionLLM

- id: arxiv:2203.17270
  type: paper
  publisher: ECCV 2022
  image: images/2203.17270.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/zhiqi-li/BEVFormer)-
    \ The 6th most influential paper in ECCV 2022-
    \ The 100 most cited AI papers of 2022-
    \ Automatic-driving competition Waymo 2022 champion"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2203.17270
    - type: source
      text: Code
      link: https://github.com/zhiqi-li/BEVFormer

- id: arxiv:2211.10439
  type: paper
  publisher: CVPR 2023 (Highlight)
  image: images/2211.10439.png
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2211.10439

- id: arxiv:2212.10156
  type: paper
  publisher: CVPR 2023 (Best Paper Award)
  image: images/2212.10156.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/opendrivelab/uniad)<br><a href=\"https://cvpr2023.thecvf.com/Conferences/2023/Awards\"><button style=\"padding: 10px; display: inline-flex; font-family: var(--heading); font-weight: var(--semi-bold); background-color: #0ea5e9; color: white; border: none; border-radius: 10px; margin: 5px; gap: 10px; max-width: calc(100% - 5px - 5px); cursor: pointer;\">BEST PAPER</button></a>"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2212.10156
    - type: source
      text: Code
      link: https://github.com/opendrivelab/uniad

- id: arxiv:2305.17144
  type: paper
  publisher: Arxiv Tech Report 2023
  image: images/2305.17144.png
  description: "![GitHub Repo stars](https://img.shields.io/github/stars/OpenGVLab/GITM)"
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2305.17144
    - type: source
      text: Code
      link: https://github.com/OpenGVLab/GITM

# ------ Above are the highlight papers ------

- id: arxiv:2308.01907
  type: paper
  publisher: Arxiv Tech Report 2023
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2308.01907
    - type: source
      text: Code
      link: https://github.com/opengvlab/all-seeing

- id: arxiv:2211.05781
  type: paper
  publisher: Arxiv Tech Report 2022
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2211.05781
    - type: source
      text: Code
      link: https://github.com/opengvlab/stm-evaluation

- id: arxiv:2211.09807
  type: paper
  publisher: CVPR 2023 (Highlight)
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2211.09807
    - type: source
      text: Code
      link: https://github.com/OpenGVLab/M3I-Pretraining

- id: arxiv:2206.01204
  type: paper
  publisher: CVPR 2023 (Highlight)
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2206.01204
    - type: source
      text: Code
      link: https://github.com/fundamentalvision/siamese-image-modeling

- id: arxiv:2111.13579
  type: paper
  publisher: ECCV 2022
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2111.13579
    - type: source
      text: Code
      link: https://github.com/ChangyaoTian/VL-LTR

- id: arxiv:2112.05141
  type: paper
  publisher: CVPR 2022
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2112.05141
    - type: source
      text: Code
      link: https://github.com/fundamentalvision/unigrad

- id: arxiv:2103.14026
  type: paper
  publisher: CVPR 2022
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2103.14026

- id: https://openreview.net/forum?id=hLTZCN7f3M-
  type: paper
  publisher: NeurIPS 2021
  buttons:
    - type: paper
      link: https://openreview.net/forum?id=hLTZCN7f3M-
    - type: source
      text: Code
      link: https://github.com/fundamentalvision/parameterized-ap-loss

- id: arxiv:2011.12953
  type: paper
  publisher: CVPR 2021
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2011.12953

- id: arxiv:2010.07930
  type: paper
  publisher: ICLR 2021
  buttons:
    - type: paper
      link: https://arxiv.org/abs/2010.07930
    - type: source
      text: Code
      link: https://github.com/fundamentalvision/Auto-Seg-Loss

- id: arxiv:1910.02940
  type: paper
  publisher: ICLR 2020
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1910.02940
    - type: source
      text: Code
      link: https://github.com/hangg7/deformable-kernels/

- id: arxiv:1904.05873
  type: paper
  publisher: ICCV 2019
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1904.05873

- id: arxiv:1811.11167
  type: paper
  publisher: Arxiv Tech Report 2018
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1811.11167

- id: arxiv:1804.05830
  type: paper
  publisher: Arxiv Tech Report 2018
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1804.05830

- id: arxiv:1803.07066
  type: paper
  publisher: ECCV 2018
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1803.07066

- id: arxiv:1603.08678
  type: paper
  publisher: ECCV 2016
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1603.08678

- id: arxiv:1412.6296
  type: paper
  publisher: ICLR 2015
  buttons:
    - type: paper
      link: https://arxiv.org/abs/1412.6296
    - type: source
      text: Code
      link: http://www.stat.ucla.edu/~yang.lu/Project/generativeCNN/main.html
